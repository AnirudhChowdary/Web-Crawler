{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nte78IyUZmYK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import urllib.request\n",
        "import urllib.error\n",
        "\n",
        "def sleep(timeout, retry=3):\n",
        "    def the_real_decorator(function):\n",
        "        def wrapper(*args, **kwargs):\n",
        "            retries = 0\n",
        "            while retries < retry:\n",
        "                try:\n",
        "                    value = function(*args, **kwargs)\n",
        "                    if value is None:\n",
        "                        return\n",
        "                except:\n",
        "                    print(f'Sleeping for {timeout} seconds')\n",
        "                    time.sleep(timeout)\n",
        "                    retries += 1\n",
        "        return wrapper\n",
        "    return the_real_decorator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = []\n",
        "def Duplicates_check(str1):\n",
        "  check = 0 \n",
        "  print(\" duplicate check for \"+str1)\n",
        "  \n",
        "  if(str1 not in duplicates):\n",
        "    duplicates.append(str1)\n",
        "    return 1\n",
        "  else :\n",
        "    return 0\n"
      ],
      "metadata": {
        "id": "kZdbQt-1Aq7y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk   "
      ],
      "metadata": {
        "id": "pQdOzwjGhop1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQpnJCHMydCN",
        "outputId": "1202942c-eb00-4700-a3dd-c1af36dc0c60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting words from http://mobile.unt.edu/\n",
            "Documents/file0.txt\n",
            "Extracting words from https://www.google.com/maps/place/University+of+North+Texas/@33.2074925,-97.1547749,17\n",
            "Documents/file1.txt\n",
            "Extracting words from http://www.unt.edu\n",
            "Documents/file2.txt\n",
            "Extracting words from https://admissions.unt.edu/\n",
            "Documents/file3.txt\n",
            "Extracting words from https://research.unt.edu/\n",
            "Documents/file4.txt\n",
            "Extracting words from https://meangreensports.com/\n",
            "Documents/file5.txt\n",
            "Extracting words from http://giving.unt.edu/\n",
            "Documents/file6.txt\n",
            "Extracting words from https://my.unt.edu/\n",
            "Documents/file7.txt\n",
            "Extracting words from https://canvas.unt.edu/\n",
            "Documents/file8.txt\n",
            "Extracting words from https://eagleconnect.unt.edu/\n",
            "Documents/file9.txt\n",
            "Extracting words from https://canvas.unt.edu\n",
            "Documents/file10.txt\n",
            "Extracting words from https://www.unt.edu/story/unt-clearly-university-north-texas\n",
            "Documents/file11.txt\n",
            "Extracting words from https://tours.unt.edu/\n",
            "Documents/file12.txt\n",
            "Extracting words from https://apply.unt.edu/\n",
            "Documents/file13.txt\n",
            "Extracting words from http://apply.unt.edu/\n",
            "Documents/file14.txt\n",
            "Extracting words from http://transfernow.unt.edu/\n",
            "Documents/file15.txt\n",
            "Extracting words from http://tgs.unt.edu/future-students\n",
            "Documents/file16.txt\n",
            "Extracting words from http://admissions.unt.edu/international\n",
            "Documents/file17.txt\n",
            "Extracting words from https://online.unt.edu/\n",
            "Documents/file18.txt\n",
            "Extracting words from https://terryscholars.unt.edu/incoming-freshmen/overview\n",
            "Documents/file19.txt\n",
            "Extracting words from http://admissions.unt.edu/freshman\n",
            "Documents/file20.txt\n",
            "Extracting words from https://registration.unt.edu/\n",
            "Documents/file21.txt\n",
            "Extracting words from https://studentaffairs.unt.edu/orientation-and-transition-programs/programs/orientation/about/register\n",
            "Documents/file22.txt\n",
            "Extracting words from http://tours.unt.edu\n",
            "Documents/file23.txt\n",
            "Extracting words from http://admissions.unt.edu\n",
            "Documents/file24.txt\n",
            "Extracting words from https://frisco.unt.edu/location/branch-campus\n",
            "Documents/file25.txt\n",
            "Extracting words from https://twitter.com/UNTsocial\n",
            "Documents/file26.txt\n",
            "Extracting words from https://www.unt.edu/oklahomatuition\n",
            "Documents/file27.txt\n",
            "Extracting words from https://twitter.com/hashtag/UNTproud?src=hash\n",
            "Documents/file28.txt\n",
            "Extracting words from http://social.unt.edu/connect-other-students\n",
            "Documents/file29.txt\n",
            "Extracting words from https://twitter.com/UNTPrez/status/1395802978137911307\n",
            "Documents/file30.txt\n",
            "Extracting words from http://frisco.unt.edu/\n",
            "Documents/file31.txt\n",
            "Extracting words from https://twitter.com/UNTUnion\n",
            "Documents/file32.txt\n",
            "Extracting words from http://apply.unt.edu/campus-life\n",
            "Documents/file33.txt\n",
            "Extracting words from https://news.unt.edu/news-releases/frisco-startup-gets-fda-approval-covid-breathalyzer-after-teaming-unt-researcher\n",
            "Documents/file34.txt\n",
            "Extracting words from http://news.unt.edu\n",
            "Documents/file35.txt\n",
            "Extracting words from https://news.unt.edu/news-releases/unt-partners-podium-education-global-tech-experiential-training\n",
            "Documents/file36.txt\n",
            "Extracting words from https://news.unt.edu/news-releases/unt-engineering-and-logistics-researchers-receive-nasa-high-volume-manufacturing-and\n",
            "Documents/file37.txt\n",
            "Extracting words from https://news.unt.edu/news-releases/unt-mpa-programs-named-top-20-nationally-new-rankings\n",
            "Documents/file38.txt\n",
            "Extracting words from https://news.unt.edu/news-releases/unt-researcher-says-graphic-novels-could-be-valuable-tool-improve-health-literacy\n",
            "Documents/file39.txt\n",
            "Extracting words from https://admissions.unt.edu/tuition-costs-aid\n",
            "Documents/file40.txt\n",
            "Extracting words from https://247wallst.com/special-report/2017/09/11/25-best-college-towns-in-america/5/\n",
            "Documents/file41.txt\n",
            "Extracting words from https://www.unt.edu/rankings\n",
            "Documents/file42.txt\n",
            "Extracting words from https://www.facebook.com/northtexas\n",
            "Documents/file43.txt\n",
            "Extracting words from https://twitter.com/untnews\n",
            "Documents/file44.txt\n",
            "Extracting words from https://www.youtube.com/user/universitynorthtexas\n",
            "Documents/file45.txt\n",
            "HTTPError: 429 for https://www.instagram.com/UNT/\n",
            "Extracting words from https://www.flickr.com/photos/unt/\n",
            "Documents/file46.txt\n",
            "HTTPError: 999 for https://www.linkedin.com/edu/school?id=19538&trk=edu-cp-title\n",
            "Extracting words from http://social.unt.edu/social-media-directory\n",
            "Documents/file47.txt\n",
            "Extracting words from https://www.unt.edu\n",
            "Documents/file48.txt\n",
            "Extracting words from http://admissions.unt.edu/\n",
            "Documents/file49.txt\n",
            "Extracting words from http://tours.unt.edu/\n",
            "Documents/file50.txt\n",
            "Extracting words from https://admissions.unt.edu/requestinfo\n",
            "Documents/file51.txt\n",
            "Extracting words from https://my.unt.edu\n",
            "Documents/file52.txt\n",
            "Extracting words from https://library.unt.edu/\n",
            "Documents/file53.txt\n",
            "Extracting words from http://calendar.unt.edu/\n",
            "Documents/file54.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting words from http://maps.unt.edu/\n",
            "Documents/file55.txt\n",
            "Extracting words from https://news.unt.edu/\n",
            "Documents/file56.txt\n",
            "Extracting words from https://jobs.untsystem.edu\n",
            "Documents/file57.txt\n",
            "Extracting words from https://speakout.unt.edu/\n",
            "Documents/file58.txt\n",
            "Extracting words from https://idea.unt.edu/\n",
            "Documents/file59.txt\n",
            "Extracting words from https://idea.unt.edu/title-ix\n",
            "Documents/file60.txt\n",
            "Extracting words from https://healthalerts.unt.edu\n",
            "Documents/file61.txt\n",
            "Extracting words from https://goo.gl/maps/7dcFSk4mPqu\n",
            "Documents/file62.txt\n",
            "Extracting words from https://goo.gl/maps/gmkVRXCJqCq\n",
            "Documents/file63.txt\n",
            "Extracting words from http://policy.unt.edu/policy/14-005\n",
            "Documents/file64.txt\n",
            "Extracting words from https://sao.fraud.texas.gov\n",
            "Documents/file65.txt\n",
            "Extracting words from http://policy.unt.edu/policy/04-002\n",
            "Documents/file66.txt\n",
            "Extracting words from https://cm.maxient.com/reportingform.php?UnivofNorthTexas&layout_id=6\n",
            "Documents/file67.txt\n",
            "Extracting words from https://deanofstudents.unt.edu/conduct/hazing\n",
            "Documents/file68.txt\n",
            "Extracting words from https://secure.ethicspoint.com/domain/media/en/gui/56566/index.html\n",
            "Documents/file69.txt\n",
            "Extracting words from https://gov.texas.gov/\n",
            "Documents/file70.txt\n",
            "Extracting words from https://itss.untsystem.edu/divisions/mrs/it-standards/linking-notice.php\n",
            "Documents/file71.txt\n",
            "Extracting words from https://www.tsl.texas.gov/trail/index.html\n",
            "Documents/file72.txt\n",
            "Extracting words from https://veterans.portal.texas.gov/\n",
            "Documents/file73.txt\n",
            "Extracting words from https://www.unt.edu/compact-with-texans\n",
            "Documents/file74.txt\n",
            "Extracting words from https://texas.gov/\n",
            "Documents/file75.txt\n",
            "Extracting words from https://www.untsystem.edu/\n",
            "Documents/file76.txt\n",
            "Extracting words from https://www.untdallas.edu/\n",
            "Documents/file77.txt\n",
            "HTTPError: 403 for https://www.unthsc.edu/\n",
            "['http://mobile.unt.edu/', 'https://www.google.com/maps/place/University+of+North+Texas/@33.2074925,-97.1547749,17', 'http://www.unt.edu', 'https://admissions.unt.edu/', 'https://research.unt.edu/', 'https://meangreensports.com/', 'http://giving.unt.edu/', 'https://my.unt.edu/', 'https://canvas.unt.edu/', 'https://eagleconnect.unt.edu/', 'https://canvas.unt.edu', 'https://www.unt.edu/story/unt-clearly-university-north-texas', 'https://tours.unt.edu/', 'https://apply.unt.edu/', 'http://apply.unt.edu/', 'http://transfernow.unt.edu/', 'http://tgs.unt.edu/future-students', 'http://admissions.unt.edu/international', 'https://online.unt.edu/', 'https://terryscholars.unt.edu/incoming-freshmen/overview', 'http://admissions.unt.edu/freshman', 'https://registration.unt.edu/', 'https://studentaffairs.unt.edu/orientation-and-transition-programs/programs/orientation/about/register', 'http://tours.unt.edu', 'http://admissions.unt.edu', 'https://frisco.unt.edu/location/branch-campus', 'https://twitter.com/UNTsocial', 'https://www.unt.edu/oklahomatuition', 'https://twitter.com/hashtag/UNTproud?src=hash', 'http://social.unt.edu/connect-other-students', 'https://twitter.com/UNTPrez/status/1395802978137911307', 'http://frisco.unt.edu/', 'https://twitter.com/UNTUnion', 'http://apply.unt.edu/campus-life', 'https://news.unt.edu/news-releases/frisco-startup-gets-fda-approval-covid-breathalyzer-after-teaming-unt-researcher', 'http://news.unt.edu', 'https://news.unt.edu/news-releases/unt-partners-podium-education-global-tech-experiential-training', 'https://news.unt.edu/news-releases/unt-engineering-and-logistics-researchers-receive-nasa-high-volume-manufacturing-and', 'https://news.unt.edu/news-releases/unt-mpa-programs-named-top-20-nationally-new-rankings', 'https://news.unt.edu/news-releases/unt-researcher-says-graphic-novels-could-be-valuable-tool-improve-health-literacy', 'https://admissions.unt.edu/tuition-costs-aid', 'https://247wallst.com/special-report/2017/09/11/25-best-college-towns-in-america/5/', 'https://www.unt.edu/rankings', 'https://www.facebook.com/northtexas', 'https://twitter.com/untnews', 'https://www.youtube.com/user/universitynorthtexas', 'https://www.instagram.com/UNT/', 'https://www.flickr.com/photos/unt/', 'https://www.linkedin.com/edu/school?id=19538&trk=edu-cp-title', 'http://social.unt.edu/social-media-directory', 'https://www.unt.edu', 'http://admissions.unt.edu/', 'http://tours.unt.edu/', 'https://admissions.unt.edu/requestinfo', 'https://my.unt.edu', 'https://library.unt.edu/', 'http://calendar.unt.edu/', 'http://maps.unt.edu/', 'https://news.unt.edu/', 'https://jobs.untsystem.edu', 'https://speakout.unt.edu/', 'https://idea.unt.edu/', 'https://idea.unt.edu/title-ix', 'https://healthalerts.unt.edu', 'https://goo.gl/maps/7dcFSk4mPqu', 'https://goo.gl/maps/gmkVRXCJqCq', 'http://policy.unt.edu/policy/14-005', 'https://sao.fraud.texas.gov', 'http://policy.unt.edu/policy/04-002', 'https://cm.maxient.com/reportingform.php?UnivofNorthTexas&layout_id=6', 'https://deanofstudents.unt.edu/conduct/hazing', 'https://secure.ethicspoint.com/domain/media/en/gui/56566/index.html', 'https://gov.texas.gov/', 'https://itss.untsystem.edu/divisions/mrs/it-standards/linking-notice.php', 'https://www.tsl.texas.gov/trail/index.html', 'https://veterans.portal.texas.gov/', 'https://www.unt.edu/compact-with-texans', 'https://texas.gov/', 'https://www.untsystem.edu/', 'https://www.untdallas.edu/', 'https://www.unthsc.edu/']\n"
          ]
        }
      ],
      "source": [
        "from operator import add\n",
        "from urllib.request import urlopen\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import requests\n",
        "import ssl\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from urllib3.exceptions import InsecureRequestWarning\n",
        "from urllib3 import disable_warnings\n",
        "\n",
        "\n",
        "\n",
        "import requests\n",
        "import lxml.html as lh\n",
        "from bs4 import UnicodeDammit\n",
        "\n",
        "HEADERS = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "# get all the links from unt.edu\n",
        "def getLinks(url):\n",
        "     #html = urlopen(url).read()\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36 QIHU 360SE'}\n",
        "    html = requests.get(url, headers = headers)\n",
        "    soup = BeautifulSoup(html.content, \"html.parser\")\n",
        "    links = []\n",
        "    for link in soup.find_all('a'):\n",
        "        links.append(link.get('href'))\n",
        "    return links\n",
        "\n",
        "# extract words from a link\n",
        "def getWords(url):\n",
        "  try:\n",
        "    html = urlopen(url).read()\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    for data in soup(['style', 'script']):\n",
        "        # Remove tage of the soup \n",
        "        data.decompose()\n",
        "\n",
        "    text = ' '.join(soup.stripped_strings)\n",
        "    #print(text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    words = text.split()\n",
        "    return words\n",
        "  except urllib.error.HTTPError as e: \n",
        "        print(f'HTTPError: {e.code} for {url}')\n",
        "        sleep(1)\n",
        "        return\n",
        "        #raise e\n",
        "\n",
        "# save words into a file\n",
        "def saveWords(words, filename):\n",
        "  if words != None:\n",
        "    f = open(filename, 'w')\n",
        "    for word in words:\n",
        "        f.write(word + ' ')\n",
        "    f.close()\n",
        "\n",
        "# main function\n",
        "def main():\n",
        "    url = 'http://www.unt.edu'\n",
        "    links = getLinks(url)\n",
        "    i = 0\n",
        "    non_duplicates = []\n",
        "    for link in links:\n",
        "        if link is not None:\n",
        "            if link.startswith('http'):\n",
        "                #print(link)\n",
        "                #print(Duplicates)\n",
        "                if link not in non_duplicates : \n",
        "                  non_duplicates.append(link) \n",
        "                  words = getWords(link)\n",
        "                  if( words is None):\n",
        "                    continue\n",
        "                  print('Extracting words from ' + link)\n",
        "                  if not os.path.exists('Documents'):\n",
        "                    os.makedirs('Documents')\n",
        "                  filename = 'Documents/file' + str(i) + '.txt'\n",
        "                  print(filename)\n",
        "                  saveWords(words, filename)\n",
        "                  i += 1\n",
        "                # save the link to a file\n",
        "                  f = open('links.txt', 'a')\n",
        "                  f.write(link + '\\n')\n",
        "    print(non_duplicates)\n",
        "if __name__ == '__main__':\n",
        "    ssl._create_default_https_context = ssl._create_unverified_context\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MKsBkGM8euM",
        "outputId": "ece2f4de-58f9-46ce-9bf5-945e9f7a4fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYfRbKuWyRDa",
        "outputId": "fe58567f-443e-40bb-ccc3-14d4bd781dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query: information retrieval\n",
            "https://www.unt.edu\n",
            "\n",
            "https://studentaffairs.unt.edu/orientation-and-transition-programs/programs/orientation/about/register\n",
            "\n",
            "https://www.unt.edu/story/unt-clearly-university-north-texas\n",
            "\n",
            "http://tours.unt.edu\n",
            "\n",
            "https://goo.gl/maps/gmkVRXCJqCq\n",
            "\n",
            "http://tours.unt.edu/\n",
            "\n",
            "http://www.unt.edu\n",
            "\n",
            "http://admissions.unt.edu/\n",
            "\n",
            "http://policy.unt.edu/policy/14-005\n",
            "\n",
            "https://sao.fraud.texas.gov\n",
            "\n",
            "Enter your query: cloud\n",
            "could not find this word\n",
            "Enter your query: unt union\n",
            "http://maps.unt.edu/\n",
            "\n",
            "https://studentaffairs.unt.edu/orientation-and-transition-programs/programs/orientation/about/register\n",
            "\n",
            "https://www.unt.edu/story/unt-clearly-university-north-texas\n",
            "\n",
            "https://news.unt.edu/news-releases/frisco-startup-gets-fda-approval-covid-breathalyzer-after-teaming-unt-researcher\n",
            "\n",
            "https://www.untdallas.edu/\n",
            "\n",
            "http://social.unt.edu/social-media-directory\n",
            "\n",
            "https://meangreensports.com/\n",
            "\n",
            "https://www.google.com/maps/place/University+of+North+Texas/@33.2074925,-97.1547749,17\n",
            "\n",
            "http://admissions.unt.edu/\n",
            "\n",
            "https://twitter.com/hashtag/UNTproud?src=hash\n",
            "\n",
            "Enter your query: trust\n",
            "https://veterans.portal.texas.gov/\n",
            "\n",
            "https://deanofstudents.unt.edu/conduct/hazing\n",
            "\n",
            "https://canvas.unt.edu\n",
            "\n",
            "https://gov.texas.gov/\n",
            "\n",
            "https://twitter.com/UNTsocial\n",
            "\n",
            "http://social.unt.edu/social-media-directory\n",
            "\n",
            "https://www.untsystem.edu/\n",
            "\n",
            "https://www.google.com/maps/place/University+of+North+Texas/@33.2074925,-97.1547749,17\n",
            "\n",
            "https://texas.gov/\n",
            "\n",
            "https://247wallst.com/special-report/2017/09/11/25-best-college-towns-in-america/5/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "\n",
        "# get all the files from Documents folder\n",
        "def getFiles():\n",
        "    files = []\n",
        "    for file in os.listdir('Documents'):\n",
        "        files.append(file)\n",
        "    return files\n",
        "\n",
        "# read files from Documents folder\n",
        "def readFile(filename):\n",
        "    f = open('Documents/' + filename, 'r')\n",
        "    text = f.read()\n",
        "    f.close()\n",
        "    return text\n",
        "\n",
        "# preprocess the text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_text = []\n",
        "    for w in word_tokens:\n",
        "        if w not in stop_words:\n",
        "            filtered_text.append(w)\n",
        "    ps = PorterStemmer()\n",
        "    stemmed_text = []\n",
        "    for w in filtered_text:\n",
        "        stemmed_text.append(ps.stem(w))\n",
        "    #print(stemmed_text)\n",
        "    return stemmed_text\n",
        "\n",
        "# get the term frequency of each word in a file\n",
        "def getTermFrequency(words):\n",
        "    tf = {}\n",
        "    for word in words:\n",
        "        if word in tf:\n",
        "            tf[word] += 1\n",
        "        else:\n",
        "            tf[word] = 1\n",
        "    return tf\n",
        "\n",
        "# get the inverse document frequency of each word in all files\n",
        "def getInverseDocumentFrequency(files):\n",
        "    idf = {}\n",
        "    for file in files:\n",
        "        text = readFile(file)\n",
        "        words = preprocess(text)\n",
        "        for word in words:\n",
        "            if word in idf:\n",
        "                idf[word] += 1\n",
        "            else:\n",
        "                idf[word] = 1\n",
        "    for word in idf:\n",
        "        idf[word] = math.log(len(files) / idf[word])\n",
        "    return idf\n",
        "\n",
        "# get the tf-idf of each word in a file\n",
        "def getTFIDF(tf, idf):\n",
        "    tfidf = {}\n",
        "    for word in tf:\n",
        "      if( word in tf and  word in idf) :\n",
        "        tfidf[word] = tf[word] * idf[word]\n",
        "    return tfidf\n",
        "\n",
        "# get the cosine similarity of two files\n",
        "def getCosineSimilarity(tfidf1, tfidf2):\n",
        "    numerator = 0\n",
        "    denominator1 = 0\n",
        "    denominator2 = 0\n",
        "    for word in tfidf1:\n",
        "        if word in tfidf2:\n",
        "            numerator += tfidf1[word] * tfidf2[word]\n",
        "        denominator1 += tfidf1[word] ** 2\n",
        "    for word in tfidf2:\n",
        "        denominator2 += tfidf2[word] ** 2\n",
        "    denominator = math.sqrt(denominator1) * math.sqrt(denominator2)\n",
        "    if denominator == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return numerator / denominator\n",
        "\n",
        "# get the top 10 results\n",
        "def getTop10Results(query, files, idf):\n",
        "    query = preprocess(query)\n",
        "    query_tf = getTermFrequency(query)\n",
        "    query_tfidf = getTFIDF(query_tf, idf)\n",
        "    results = {}\n",
        "    for file in files:\n",
        "        text = readFile (file)\n",
        "        words = preprocess(text)\n",
        "        tf = getTermFrequency(words)\n",
        "        tfidf = getTFIDF(tf, idf)\n",
        "        results[file] = getCosineSimilarity(query_tfidf, tfidf)\n",
        "    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_results[:10]\n",
        "\n",
        "# main function\n",
        "def main():\n",
        "    links = []\n",
        "    resultLinks = []\n",
        "    f = open('links.txt', 'r')\n",
        "    for line in f:\n",
        "        links.append(line)\n",
        "    files = getFiles()\n",
        "    idf = getInverseDocumentFrequency(files)\n",
        "    while True:\n",
        "        query = input('Enter your query: ')\n",
        "        if query == 'exit':\n",
        "            sys.exit()\n",
        "        results = getTop10Results(query, files, idf)\n",
        "        for result in results:\n",
        "            # print(result)\n",
        "            num = re.findall(r'\\d+', result[0])\n",
        "            if(result[1]>0) :\n",
        "              resultLinks.append(links[int(num[0]) - 1])\n",
        "        # print(resultLinks)\n",
        "        if(len(resultLinks)>0 ):\n",
        "          for l in set(resultLinks):\n",
        "            print(l)\n",
        "        else :\n",
        "           print(\"could not find this word\")\n",
        "        resultLinks = []\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}